{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iwd-2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkSGVSxZDrx8",
        "colab_type": "text"
      },
      "source": [
        "Tips:\n",
        "\n",
        "* Enable a GPU in Colab before running this notebook. *Edit -> Notebook settings -> Hardware accelerator -> GPU.*\n",
        "\n",
        "* Should you need to reset your Colab environment to a clean state, use *Runtime -> Factory reset runtime*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v5mm4amQRrm",
        "colab_type": "text"
      },
      "source": [
        "# International Women's Day 2020: Training Neural Networks\n",
        "\n",
        "Welcome! This notebook contains tutorials and short exercises. \n",
        "\n",
        "IWD workshops are of different lengths around the world (unless yours is a full day, you are not expected to complete this entire notebook). Your instructor will guide you through the sections we'll explore today. Our goals are for you to dive in, have fun, and to gain experience training neural networks. \n",
        "\n",
        "Note: If you're new to Deep Learning, this is a *lot* of material to see all at once. Of course, no one is expected to learn it all in one day. There are educational resources at the end for you to continue learning, and you can complete the sections we don't get to today at home. \n",
        "\n",
        "Here's an outline of what we'll cover.\n",
        "\n",
        "**Part 1: Training neural networks**\n",
        "\n",
        "* You'll train a neural network to classify handwritten digits. This is the \"hello world\" of computer vision, and a great place to begin if you're new to the subject.\n",
        "\n",
        "* You'll train a convolutional neural network to classify images of cats and dogs, using a real-world dataset.\n",
        "\n",
        "* Next, you'll use techniques like data augmentation and Dropout to reduce overfitting.\n",
        "\n",
        "**Part 2: Interpreting neural networks**\n",
        "\n",
        "* (Advanced) In this section, you will see a minimal version of [DeepDream](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html), an experiment that asks a neural network to show us some of the complex features it has learned to detect. Deep Learning is a type of representation learning (a CNN automatically learns a feature hierarchy from pixels -> lines -> shapes -> textures). Each layer learns increasingly complex features, with later layers eventually responding to complex objects (like eyes). You'll be able to see some of those after running this code.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "* Each section contains a tutorial, then a short exercise. Your instructor will walk you through the tutorial, then you will work on the exercise. You can find solutions for each exercise in a comment.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jciXPo_3C3Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"You are using TensorFlow version\", tf.__version__)\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "  print(\"You have a GPU enabled.\")\n",
        "else:\n",
        "  print(\"Enable a GPU before running this notebook.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2esj4IQFIRN",
        "colab_type": "text"
      },
      "source": [
        "Note: Colab has a variety of GPU types available (each new  instance is assigned one randomly, depending on availability). To see which type of GPU you have, you can run ```!nvidia-smi``` in a code cell. Some are quite fast!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKbWlnHYMbKB",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 1: MNIST\n",
        "\n",
        "Training an image classifier on the MNIST dataset of handwritten digits is considered the \"hello world\" of computer vision. In this tutorial, you will download the dataset, then train a linear model, a neural network, and a deep neural network to classify it. \n",
        "\n",
        "The code below is based on a longer tutorial on [tensorflow.org](https://www.tensorflow.org/tutorials/keras/classification), which you can read later for more background."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6w-q4DDdKRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk5WiZoldYxG",
        "colab_type": "text"
      },
      "source": [
        "## Download the MNIST dataset\n",
        "MNIST contains 70,000 grayscale images in 10 categories. The images are low resolution (28 by 28 pixels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF6B1mtqdQLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz7X2_VSdoTk",
        "colab_type": "text"
      },
      "source": [
        "There are 60,000 images in the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ziZ_hgdVuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOCEVIxfdrkm",
        "colab_type": "text"
      },
      "source": [
        "And 10,000 in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "161xulFtdtLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8tV2hZedwbf",
        "colab_type": "text"
      },
      "source": [
        "Each label is an integer between 0-9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNlj_WDqd07Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHel6Cn5d7fb",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data\n",
        "The pixel values in the images range between 0 and 255. Let's convert them to between 0 and 1 before feeding them to the network. To do so, divide the values by 255. It's important that the training set and the testing set are preprocessed in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rPiwYVeF-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7n2On4UeIHV",
        "colab_type": "text"
      },
      "source": [
        "Let's display the first 25 images from the training set, and display the label below each image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7lAScI-eNdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilarSa6DeV0j",
        "colab_type": "text"
      },
      "source": [
        "## Build the model\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model. We will start with a single Dense layer. \n",
        "\n",
        "### Set up the layers\n",
        "\n",
        "The basic building block of a neural network is the layer. Layers extract representations from the data fed into them. For example, the first layer in a network might learn to detect edges (combinations of pixels), and the next layer may learn to detect lines (combinations of edges). Most of deep learning consists of chaining together simple layers. Most layers, such as [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), have parameters that are learned during training.\n",
        "\n",
        "### Create a multiclass logistic regression model\n",
        "\n",
        "This model contains a single Dense layer. It is not a neural network yet, it is equivilent to multiclass logistic regression. If you add another layer, it will become a neural network. You will do that in an exercise below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSHV4al-e_eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiH9Th8IfPJ7",
        "colab_type": "text"
      },
      "source": [
        "The first layer in this network, [tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data. This is necessary since Dense layers require arrays as input.\n",
        "\n",
        "After the pixels are flattened, this model consists of a single Dense layer. This is a densely connected, or fully connected, neural layer. The Dense layer has 10 neurons with softmax activation. This returns an array of 10 probability scores that sum to 1. \n",
        "\n",
        "After classifying an image, each neuron will contains a score that indicates the probability that the current image belongs to one of the 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFAUK1K-gFvz",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
        "\n",
        "*Loss function* — This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
        "\n",
        "*Optimizer* — This is how the model is updated based on the data it sees and its loss function.\n",
        "\n",
        "*Metrics* — Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKclqoN7gMTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqV1ZI6ogUJo",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "1. Feed the training data to the model. In this example, the training data is in the ```train_images``` and ```train_labels``` arrays.\n",
        "\n",
        "1. The model learns to associate images and labels.\n",
        "\n",
        "1. You ask the model to make predictions about a test set—in this example, the ```test_images``` array.\n",
        "\n",
        "1. Verify that the predictions match the labels from the ```test_labels``` array.\n",
        "\n",
        "To begin training, call the ```model.fit``` method — so called because it \"fits\" the model to the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd21x84Gef2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCttErqEgw4C",
        "colab_type": "text"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.90 (or 90%) on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es55EpWvg1HF",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate accuracy\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFoghgfRg4B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5-Ej3Tg7cU",
        "colab_type": "text"
      },
      "source": [
        "It turns out that the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy represents overfitting. Overfitting is when a machine learning model performs worse on new, previously unseen inputs than on the training data. An overfitted model \"memorizes\" the training data—with less accuracy on testing data. \n",
        "\n",
        "You will learn more about how to mitigate overfitting in the next tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rheqL8L2hBxM",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions\n",
        "With the model trained, you can use it to make predictions about some images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wIrXBw2hDTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DJkopTnhEuP",
        "colab_type": "text"
      },
      "source": [
        "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtCv-McahE6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlebz80khI_O",
        "colab_type": "text"
      },
      "source": [
        "A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 digits. You can see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7yzszkqhMRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.argmax(predictions[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts6YwkHIhTOy",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 1: MNIST\n",
        "\n",
        "In the above tutorial, you used a single Dense layer to reach about 90% accuracy. Now, let's transform your model into a neural network to reach about 95% accuracy. To do so, add a second Dense layer, then compile and train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEQfxITliuBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    # TODO: your code here\n",
        "    # Add a Dense layer with 128 neurons and relu activation.\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNXJ7A2Ti_F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, compile your new model by uncommenting this code \n",
        "# model.compile(optimizer='adam',\n",
        "#              loss='sparse_categorical_crossentropy',\n",
        "#              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo8FZFFMjGO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finally, train your model by uncommenting this code\n",
        "# model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O04h2fCjPwN",
        "colab_type": "text"
      },
      "source": [
        "**Questions to think about:**\n",
        "- How does the accuracy of your neural network compare with your first model? \n",
        "- What is the effect of epochs on accuracy? On validation accuracy?\n",
        "- What is the effect of the number of neurons per layer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcK_hxuVO9Ja",
        "colab_type": "text"
      },
      "source": [
        "After completing this exercise, you will have trained a neural network. Deep learning is \"code-light, and concept-heavy\". That is to say, while there's only a few lines you need to write to train a DNN, you will spend a good deal of time studying all the different concepts involved, like gradient descent.\n",
        "\n",
        "Now, let's work with a real-world dataset of thousands of images of cats and dogs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0muBaA0fjFJn",
        "colab_type": "text"
      },
      "source": [
        "## Solution\n",
        "\n",
        "This is a neural network:\n",
        "\n",
        "```\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "This is a deep neural network:\n",
        "\n",
        "```\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "This is a deeper neural network =D\n",
        "\n",
        "```\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQjV6NPRaWYi",
        "colab_type": "text"
      },
      "source": [
        "# Game break 1: Teachable Machine\n",
        "If you'd like to, now would be a great time to try the Teachable Machine.\n",
        "\n",
        "https://teachablemachine.withgoogle.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0B8TOWwCsbM",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 2: Cats and Dogs\n",
        "In this exercise, you will train a convolutional neural network to classify images of cats and dogs, using a real-world dataset you will download, then read from disk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob2E2ZIeSbDv",
        "colab_type": "text"
      },
      "source": [
        " ## Download and explore the dataset\n",
        "\n",
        "One nice thing about running this notebook in Colab, although you are downloading large files - you are doing so on Google Cloud Platform, rather than using your local WiFi connection. This means downloads will usually be fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aPzoJnd_8QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7EocqtTHnnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origin = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=origin, extract=True)\n",
        "path_to_folder = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlL8BiAkLn1E",
        "colab_type": "text"
      },
      "source": [
        "The unzipped dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrgB9RwpShf8",
        "colab_type": "text"
      },
      "source": [
        "Create variables that point to each of these directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4b5Fsw2Lj-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(path_to_folder, 'train')\n",
        "validation_dir = os.path.join(path_to_folder, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG7DjqVkLlCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj1dSkUlLs-m",
        "colab_type": "text"
      },
      "source": [
        "Count the number of images in each directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfwja3aILv3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('Total training cat images:', num_cats_tr)\n",
        "print('Total training dog images:', num_dogs_tr)\n",
        "print('Total validation cat images:', num_cats_val)\n",
        "print('Total validation dog images:', num_dogs_val)\n",
        "print('---')\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6HxxIkqSsj6",
        "colab_type": "text"
      },
      "source": [
        "Tip: in addition to Python, you can run shell commands in Colab (for example, ```!ls $train_cats_dir```)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bOJXrOqSuoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls $train_cats_dir "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e_9iotCAH8E",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at a couple images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGVX4U4RTeF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = plt.imshow(plt.imread(os.path.join(train_cats_dir, \"cat.0.jpg\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PM8Th5UAUOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = plt.imshow(plt.imread(os.path.join(train_cats_dir, \"cat.1.jpg\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1A2CLadVnQa",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5JfskKZL716",
        "colab_type": "text"
      },
      "source": [
        "We will now need a way to read images from disk, and to format them into appropriately pre-processed floating point arrays before using them to train our network. Specifically, we will need to:\n",
        "\n",
        "- Read the image off disk.\n",
        "- Decode contents of these images and convert them into RGB arrays.\n",
        "- Convert the pixels values from integer to floating point numbers.\n",
        "- Rescale the pixel from values between 0 and 255 to values between 0 and 1 (neural networks work better with small input values - under the hood, each input is multiplied by a weight - large inputs could result in overflow).\n",
        "\n",
        "All these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbKVMUaBA14w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVOP4BOcL57E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will resize all images to the same size when they are read of disk.\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEYTv3G6L9I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rescale the pixel values from 0-255 to 0-1\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmM-kS68L-iY",
        "colab_type": "text"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff0NXGJEVPWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64 # Read a batch of 64 images at each step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zenaWVaHL_jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbgDJgcUMAeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h77qZjn2MFaZ",
        "colab_type": "text"
      },
      "source": [
        "## Display a few images and their labels\n",
        "\n",
        "Next, we will extract a batch of images from the training generator, then plot several of them with `matplotlib`. The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRkntEZ1MJev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, labels_batch = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFItkxNsp1EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (64, 150, 150, 3) means a list of 64 images, each of which is 150x150x3.\n",
        "# 3 refers to the R,G,B color channels.\n",
        "print(image_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6sb2tmtqEYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (64,) means a list of 64 numbers\n",
        "# each of these will either be 0, or 1\n",
        "print(labels_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4iqLgMjMMWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images\n",
        "# in the form of a grid with 1 row and 5 columns\n",
        "def plot_images(images):\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images, axes):\n",
        "      ax.imshow(img)\n",
        "      ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQUpgA1bMOti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_images(image_batch[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnj3jfpvTlih",
        "colab_type": "text"
      },
      "source": [
        "Let's see how we can retrieve the labels, and which class they correspond to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq1rm3jTTa9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(labels_batch[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMd_qHITcxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data_gen.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yukXvCdWMSDj",
        "colab_type": "text"
      },
      "source": [
        "## Create the model\n",
        "Your model will consist of three convolutional blocks followed by max pooling. There's a fully connected layer with 256 units on top. This model will output class probabilities (between 0 and 1) based on the `sigmoid` activation function. If the output is closer to 1, the image will be classified as a dog, otherwise a cat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAvbO8Q2BEN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dd4nHoIMGy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN8hv9ItMXNr",
        "colab_type": "text"
      },
      "source": [
        "Compile the model, and select the adam optimizer to be used for gradient descent, and binary cross entropy for our loss function (roughly, cross entropy is a way to measure the distance between the prediction we wanted the network to make, and the prediction it made)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sarE21oqMYgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB2GwR_EMZwm",
        "colab_type": "text"
      },
      "source": [
        "## Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mgFrgh-MbL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGviR2YtBq_H",
        "colab_type": "text"
      },
      "source": [
        "This model has about 5M parameters to learn. Notice, nearly all of them are in the Dense layer at the bottom!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx6po3HfMcTu",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmEm3VVwMeRg",
        "colab_type": "text"
      },
      "source": [
        "Use the `fit` method to train the network. You will train the model for 15 epochs (an epoch is one \"sweep\" over the training set, where each image is used exactly once to perform a round of gradient descent, and update the models parameters). \n",
        "\n",
        "The longer you train the model, the more accurate it will become on the training set (but the more likely it is to overfit, or memorize the training images rather than learn patterns that enable it to perform well on the unseen data in the validation set). Overfitting is a challenge you will address in the next tutorial. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ggEXVPWcxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5gKJ6eMfNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKBr3y0bueNY",
        "colab_type": "text"
      },
      "source": [
        "After training, your model is likely 90% accurate on the training set, but probably only about 70% accurate on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIYFh3m9MpvG",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate your model\n",
        "Let's create plots to help us see the difference. Accuracy on the validation data is important: it helps you estimate how well our model is likely to work on new, unseen data in the future. \n",
        "\n",
        "We will create two plots, one for accuracy, and another for loss. Roughly, loss (or error) is the inverse of accuracy (lower is better). Unlike accuracy, loss takes the confidence of a prediction into account (a confidently wrong predicitions has a higher loss than one that is only slightly wrong)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ZuxB7iMrBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBooB9-bpht",
        "colab_type": "text"
      },
      "source": [
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples, to an extent that it negatively impacts the performance of the model on new examples. This phenomenon causes overfitting. It means that the model will have a difficult time generalizing on a new dataset, or making accurate predictions on images of cats and dogs that weren't included in the training set. In the next tutorial, you'll use two techniques to mitigate overfitting: data augmentation and dropout. First, let's practice training a CNN on a new dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUU_gVFWKbXp",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2: Flowers\n",
        "\n",
        "In this exercise, you write a CNN and use it to classify five different types of flowers (sunflowers, tulips, etc). The dataset contains 1000 images in the training set, and 500 in the validation set.\n",
        "\n",
        "You will download the dataset, read and preprocess the images using ImageDataGenerator, then create, train and evaluate a model. \n",
        "\n",
        "A code outline is written for you, and there are several TODOs for you to complete, using the same pattern as the tutorial above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTIqYg8UkAO",
        "colab_type": "text"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlFiGskKKhI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origin = 'https://storage.googleapis.com/tensorflow-blog/datasets/mini_flowers.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('mini_flowers.zip', origin=origin, extract=True)\n",
        "path_to_folder = os.path.join(os.path.dirname(path_to_zip))\n",
        "\n",
        "train_dir = os.path.join(path_to_folder, \"train/\")\n",
        "val_dir = os.path.join(path_to_folder, \"val/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLLaKHvLUm5e",
        "colab_type": "text"
      },
      "source": [
        "### Read the images off disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywq7Sd-sXor-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Gv8X_LXsRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=32,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGxsPRMuUqZ9",
        "colab_type": "text"
      },
      "source": [
        "### Plot images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWxGwHvzX7LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, labels_batch = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkL2crA7X7ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image_batch[i])\n",
        "    plt.xlabel(str(labels_batch[i]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEhrQTFckgKk",
        "colab_type": "text"
      },
      "source": [
        "## Understanding one-hot labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeZMOVlAfpAh",
        "colab_type": "text"
      },
      "source": [
        "Notice the labels are in one-hot format. Let's add some code to display the class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT8PNcMiZmWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data_gen.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVsC1ryVaUz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = {v:k for k,v in train_data_gen.class_indices.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWTIFZ9EZz24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image_batch[i])\n",
        "  plt.xlabel(class_names[tf.argmax(labels_batch[i]).numpy()])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7liWGNJVdpv",
        "colab_type": "text"
      },
      "source": [
        "## Read the validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfgmDWPWVR5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Above, you created a ImageDataGenerator for the training set\n",
        "# Next, create one to read the validation images\n",
        "# For example:\n",
        "# validation_image_generator = ImageDataGenerator ...\n",
        "# val_data_gen = validation_image_generator.flow_from_directory ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejPEgXR9f7hH",
        "colab_type": "text"
      },
      "source": [
        "## Create a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTCVcwDuftS1",
        "colab_type": "text"
      },
      "source": [
        "Now, it's time to define your model. You can create a similar model to the CNN used in the tutorial above.\n",
        "\n",
        "The only difference is that the final Dense layer of your model (which classifies the data based on the features provided by the convolutional base) must use softmax activation and have five output classes:\n",
        "\n",
        "```model.add(Dense(5, activation='softmax'))```\n",
        "\n",
        "This is because we now have five different types of flowers, instead of just cats and dogs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yClBCWAIYbDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: your code here\n",
        "# Define a CNN using code similar to the above \n",
        "# For example\n",
        "# model = Sequential()\n",
        "# model.add ...\n",
        "# ...\n",
        "# The last line of your model should be:\n",
        "# model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eruSIx0zmMFv",
        "colab_type": "text"
      },
      "source": [
        "After you have defined your model, compile it by uncommenting and running this code. Important: notice that the loss has changed to ```categorical_crossentropy```. This is necessary because the labels are in one-hot format. Finally, although these loss functions sound complicated, there are only a handful for you to learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qceXRe7vYksG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.compile(optimizer='adam',\n",
        "#              loss='categorical_crossentropy',\n",
        "#              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d_hAUd0VI-I",
        "colab_type": "text"
      },
      "source": [
        "Now train your model for 10 epochs using ```model.fit```. If you like, you can try to create plots of the training and validation accuracy and loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn1EbFRnYmwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: your code here\n",
        "# For example\n",
        "# model.fit ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7unNQXamhP3",
        "colab_type": "text"
      },
      "source": [
        "If all has gone well, your model should be about 90% accurate on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9G4sDsafVer",
        "colab_type": "text"
      },
      "source": [
        "## Solution\n",
        "\n",
        "``` \n",
        "# Read the validation images\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=32,\n",
        "                                                              directory=val_dir,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')\n",
        "```\n",
        "\n",
        "```\n",
        "# Define a model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', \n",
        "                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "```\n",
        "\n",
        "```\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=10,\n",
        "    validation_data=val_data_gen,\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Tk_WFuauxw",
        "colab_type": "text"
      },
      "source": [
        "# Game break 2: Quick, Draw!\n",
        "If you'd like, now would be a good time to take a break from coding for a few minutes and try Quick, Draw!\n",
        "\n",
        "https://quickdraw.withgoogle.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3hfnxDST1we",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 3: How-to reduce overfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFrRJObuMv8d",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation\n",
        "Overfitting often occurs when there are a \"small\" number of training examples. One way to fix this problem is to augment the dataset so that it has a larger number of training examples. Data augmentation generates more training data from existing training samples by applying random transformations (for example, rotation) that yield believable-looking images. With data augmentation, the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data, and can lead to better generalization.\n",
        "\n",
        "You can implement this using the ImageDataGenerator. Specifiy different transformations to the dataset and it will take care of applying it during the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m6hO-h5nSxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paths to the cats and dogs dataset from tutorial 2\n",
        "path_to_folder = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(path_to_folder, 'train')\n",
        "validation_dir = os.path.join(path_to_folder, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIWUljgzb5dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLl4-mjKb-vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=32,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtLNwy9_b_RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show how the same image appears with different data augmentation\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plot_images(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsKX1NNpchmM",
        "colab_type": "text"
      },
      "source": [
        "We only apply data augmentation to the training examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZjPRpJkchwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQIyYxvAcknP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=32,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-s-DCjFcm1N",
        "colab_type": "text"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K34kcZfzco5M",
        "colab_type": "text"
      },
      "source": [
        "Another technique to reduce overfitting is to introduce dropout to the network. Dropout is a form of regularization that makes it more difficult for the network to memorize rare details (instead, it is forced to learn more general patterns).\n",
        "\n",
        "When you apply dropout to a layer it randomly drops out (set to zero) a number of activations during training. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly deactivates 10% of the output units in each training epoch.\n",
        "\n",
        "Create a new network architecture using Dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW2NXkclDxo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3e7ir-HcnZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', \n",
        "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlmQwrwcu4V",
        "colab_type": "text"
      },
      "source": [
        "After introducing dropout to the network, compile the model and view the layers summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L77Pt-WFcxYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEMGlbwWc254",
        "colab_type": "text"
      },
      "source": [
        "## Train your new model\n",
        "This model will need to be trained for longer (more epochs) to achieve high accuracy. As this will take some time, here we'll train for only 15 epochs so we can move on to part two of this notebook. If you like, you can continue training at home. See if your new model can achieve higher validation accuracy than your original one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jLoyPTRc2Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ktPjfbdCoC",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate your new model\n",
        "Create plots of accuracy and loss. If you compare them with your previous plots, the new model should show less overfitting than the original one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ma9lDmidMWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvojYaquePbo",
        "colab_type": "text"
      },
      "source": [
        "You can now train your new model for longer (by increasing the number of epochs) and reach higher validation accuracy. As this will take some time to train, we will leave this as an exercise for you to explore at home, and continue on to part two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anGdyrsipG2_",
        "colab_type": "text"
      },
      "source": [
        "# Game break 3: Sketch-RNN\n",
        "If you'd like, now would be a good time to take a break from coding for a few minutes and try Sketch-RNN, an experiment where a computer attempts to \"auto-complete\" your drawings, based on the Quick, Draw! dataset.\n",
        "\n",
        "https://magenta.tensorflow.org/sketch-rnn-demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5cpeEEprlOT",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 4: Deep Dream\n",
        "In this tutorial, you will see how to implement a minimal version of DeepDream, an experiment to visualize some of the features a convolutional neural network has learned to detect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ5DZa1urWkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzRZ1H47t20X",
        "colab_type": "text"
      },
      "source": [
        "## Download and display an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-Ad_AGCrQvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7I2qKIvrUyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download(url, target_size=None):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  return tf.keras.preprocessing.image.load_img(image_path, target_size)\n",
        "\n",
        "def show(img):\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "original_img = download(url, target_size=[225, 375])\n",
        "original_img = np.array(original_img)\n",
        "show(original_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNZadvf1t5Nx",
        "colab_type": "text"
      },
      "source": [
        "## Code to scale the pixel values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHZtAv0YraD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(img):\n",
        "  \"\"\" Convert RGB values from [0, 255] to [-1, 1] \"\"\"\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  img /= 128.0\n",
        "  img -= 1.\n",
        "  return img\n",
        "\n",
        "def unprocess(img):\n",
        "  \"\"\" Undo the preprocessing above \"\"\"\n",
        "  img = 255 * (img + 1.0) / 2.0\n",
        "  return tf.cast(img, tf.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD12eOvrt9wc",
        "colab_type": "text"
      },
      "source": [
        "## Import a large, pretrained CNN\n",
        "This model has been trained on ImageNet, a dataset with about 1M images in about 1K classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyNR_ayNrcRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base = tf.keras.applications.InceptionV3(weights='imagenet', \n",
        "                                              include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVrd2zgMuPPm",
        "colab_type": "text"
      },
      "source": [
        "## Choose layers to excite\n",
        "Normally, when you train a neural network, you use gradient descent to adjust the weights to minimize loss, in order to accurately classify images. In DeepDream, the trick is to use gradient descent to adjust the **image**, in order to increasingly activate certain layers from the network. You can explore different layers and see how this affects the results. You can find all the layer names using ```model.summary()```. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRFucWpkreWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = ['mixed2', 'mixed3', 'mixed4', 'mixed5']\n",
        "layers = [conv_base.get_layer(name).output for name in names]\n",
        "model = tf.keras.Model(inputs=conv_base.input, outputs=layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULXM15ysuqhj",
        "colab_type": "text"
      },
      "source": [
        "## Implement a custom loss function\n",
        "Normally, we would use cross-entropy loss (for classification), or mean squared error (for regression). Here, we'll write a loss function that describes how activated our layers were by the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAxeiGTCrgn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_loss(img):\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  losses = [tf.math.reduce_mean(act) for act in layer_activations]\n",
        "  return tf.reduce_sum(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2CRKNrau4Zh",
        "colab_type": "text"
      },
      "source": [
        "## Use the gradients to progressively modify the image to increasingly activate our layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B632smgOriZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def step(img, lr=0.001):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = calc_loss(img)\n",
        "\n",
        "  gradients = tape.gradient(loss, img)\n",
        "  gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "  # Because the gradients are in the same shape \n",
        "  # as the image, we can directly add them to it!\n",
        "  img.assign_add(gradients * lr)\n",
        "  img.assign(tf.clip_by_value(img, -1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnVu-oF0rlJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = tf.Variable(preprocess(original_img))\n",
        "\n",
        "steps = 1000\n",
        "for i in range(steps):\n",
        "  step(img)\n",
        "  if i % 200 == 0:\n",
        "    clear_output(wait=True)\n",
        "    print (\"Step {}\".format(i))\n",
        "    show(unprocess(img.numpy()))\n",
        "\n",
        "clear_output(wait=True)\n",
        "show(unprocess(img.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8vF9au2vDnp",
        "colab_type": "text"
      },
      "source": [
        "Just for fun, you can try running DeepDream on your own images, or explore different combinations of layers. DeepDream is an advanced tutorial, and our goal here is just to show you some of the fascinating (and unexpected) things you can explore with DeepLearning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JztBOYqZ6yTm",
        "colab_type": "text"
      },
      "source": [
        "# Learning more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfSulmXVQyJp",
        "colab_type": "text"
      },
      "source": [
        "To learn more about TensorFlow and Machine Learning in general, we recommend the book \"Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow\" ([GitHub](https://github.com/ageron/handson-ml2), [Website](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)). \n",
        "\n",
        "You can also stay in touch with the latest TensorFlow developments by:\n",
        "- Reading our blog http://blog.tensorflow.org/\n",
        "- Watching our YouTube channel https://www.youtube.com/tensorflow.\n",
        "- And following our Twitter account: https://twitter.com/tensorflow\n",
        "\n",
        "Thank you!"
      ]
    }
  ]
}